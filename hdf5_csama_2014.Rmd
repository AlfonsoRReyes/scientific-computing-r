---
title: "R Notebook"
output: html_notebook
---

## Intorduction to HDF5
The following code examples create an HDF5 ﬁle and ﬁll it with some random data to illustrate the functions
we can use to interact with HDF5 ﬁles.

```{r}
#We use the rhdf5 package
library(rhdf5)
filename <- tempfile() #using a temporary file
h5createFile(filename) #creating the basic file layout
```

We can use the h5ls function to list the content of the ﬁle (it is empty right now).
```{r}
h5ls(filename)
```

Let us use h5write to write some stuﬀ into the ﬁle (we use small examples, in a
nucleotide tally ﬁle the array dimensions will be several orders of magnitude
larger).

```{r}
h5write(obj = array(rnorm(20), dim=c(4,5)), file = filename, name = "/RandomArray")
h5write(obj = rpois(100, 10), file = filename, name = "/PoissonVector")
h5ls(filename)
```

As you can see each dataset shows up in the listing of the ﬁle content
(h5ls(filename)). We can use h5read to extract the data from the ﬁle again, if
we simpy specify a ﬁlename and dataset name we will retrieve the whole dataset.
Since this is a really bad idea for large scale projects (e.g. nucleotide
tallies of human samples), we can also use subsetting to extract parts of the
data. Have a look at ?h5read if you want to know more about the possible ways of
retrieving data.

```{r}
h5read(file = filename, name = "/PoissonVector")
```

```{r}
h5read(file = filename, name = "/RandomArray", index = list(2:4, 3:5))
```

This should give you a basic idea of how we can interact with HDF5 ﬁles on a low
level. Luckily there are wrapper functions in h5vc that we can use to access the
ﬁle in a more eﬃcient way. Those will be discussed in the following sections.


## Getting Started: Loading example data
We use an example set of 24 pairs of .bam ﬁles (control and case each) of which
the last 6 pairs (samples 37 through 48) are whole genome sequencing data and
the others are whole exome sequencing data. The .bam ﬁles have been subsetted to
only contain reads that span our region of interest (the NRAS gene, see below).
The samples are numbered 1 to 48 and successive samples belong together (e.g.
samples 3 and 4 are the control and case sample of the second pair, . . . ). All
samples are from human tissue and represent pairs of tumour and matched
control.

If you have not obtained a copy of the example data, do so now: while connected
to the csama wlan download 
[http://192.168.0.9/materials/04_Thursday/labs/ExampleData.zip] and extract the
contents into a subfolder of your working directory that you name ExampleData.
(You can ﬁnd out the current working directory of your R session by typing
getwd() at the R prompt.)

```{r}
getwd()
```

The .bam ﬁles should now be located in the ExampleData folder and the ﬁrst step
is to load the required packages and get the list of .bam ﬁles.￿sd

```{r}
library(h5vc)
library(Rsamtools)
```

```{r}
bamFiles <- list.files("ExampleData", "bam$") #list available data files
bamFiles <- file.path( "ExampleData", bamFiles)
# we use scanBamHeader to extract information about the contigs
chromdim <- sapply( scanBamHeader(bamFiles), function(x) x$targets )
colnames(chromdim) <- bamFiles
chromdim[,1]
```

In this tutorial we will look at a region on the genome from 115200000 to 115300000 bases on chromosome
one (overlapping the NRAS gene). Note that the .bam ﬁles we use only contain reads overlapping this region.

```{r}
chrom = "1"
startpos = 115200000
endpos = 115300000
```

```{r}
bamFiles
```


```{r}
library(BSgenome.Hsapiens.UCSC.hg19)
applyTallies(bamFiles, reference = Hsapiens[["chr1"]][startpos:endpos],
             chrom, startpos, endpos, ncycles = 10)
```


We will use the applyTallies function and if your machine has more than one core
available you could test the inﬂuence of registereing
BiocParallel::MulticoreParam objects with diﬀerent numbers of workers. It is not
expected to yield signiﬁcant speed-ups (and might even slow things down) on a
normal laptop computer. Once you move to a server with a powerful RAID setup or
a network ﬁleserver, you should be able to speed things up considerably, since
there the I/O performance will not be the limiting factor anymore. Furthermore a
big part of the used runtime goes to merging the tallies from the diﬀerent ﬁles
into one block of data, this can not be parallelised easily and remains an
inﬂuential factor in the calculation.

```{r}
library(BiocParallel) #load the library to enable parallel execution
library(BSgenome.Hsapiens.UCSC.hg19)

maxWorkers <- 2 #Set this to 1 if you want serial execution
tallyList <- list() #outputs go in this list
timeList <- list() #time measurements go here
for( nWorkers in 1:maxWorkers ){
    # set the number of concurrent jobs (see ?register for details)
    register(MulticoreParam(workers = nWorkers))
    timeList[[nWorkers]] <- system.time(
    tallyList[[nWorkers]] <- applyTallies(bamFiles, reference = Hsapiens[["chr1"]][startpos:endpos],
                 chrom, startpos, endpos, ncycles = 10)
    )
    print(paste("Tallied with", nWorkers, "parallel tasks!"))
}
```

```{r}
timeList
```

In the tally calls we just ran we didn’t specify a reference genome sequence and
the algorithm will default to a majority vote amongst all samples in this case.
In order to call also homozygous variants reliably we will have to specify the
reference sequence, since at a homozygous position the majority-vote based best
guess for what the reference base was, will in fact be the alternative allele of
the homozygous variant. Please also read ?tallyBAM for background on the
function and an explanation of the parameters. 

To avoid this problem we canprovide a DNAString to the function which will be
used as the refer- ence sequence, we get this from one of the BSGenome packages.
Note that the followingcode uses BSgenome.Hsapiens.UCSC.hg19 which has a naming
convention that is diﬀerent from the names of the choro- mosomes used in the
.bam ﬁles (“chrX” vs. “X”) and we need to ﬁx this through the call to
paste0("chr", chrom).

```{r}
# we load a reference genome and use a subset of it as a parameter to applyTallies
suppressPackageStartupMessages(library(BSgenome.Hsapiens.UCSC.hg19))
tallies <- applyTallies(
bamFiles, chrom = chrom, start = startpos, stop = endpos, ncycles = 10,
reference = BSgenome.Hsapiens.UCSC.hg19[[paste0("chr", chrom)]][startpos:endpos] )
# the first and last 10 sequencing cycles are called unreliable
str(tallies)
```

It is advisable to have a look at ?tallyBAM and ?applyTallies for an explanation of the parameters.

> Question: Try to replace the BSgenome object that is used by one that follows
ENSEMBL notation (e.g. “BSgenome.Hsapiens.NCBI.GRCh38”) and remove the
unneccessary paste command. Compare the results of
head(seqlevels(BSgenome.Hsapiens.NCBI.GRCh38)) and 
head(seqlevels(BSgenome.Hsapiens.UCSC.hg19)).

As you can see the resulting object of the call is a simple list containing a
set of arrays, which each correspond to one of the datasets we want to write to
the HDF5 ﬁle.

Now that we have created the tally object we have to write the data to an HDF5
ﬁle so that we may reference it at a later point. In this simple example case we
could always recreate the tally in each R session since it doesn’t take long,
but on a genome-wide scale this is completely impractical to do. You can see the
substantial amount of time and compute resources used to create a whole-genome
tally ﬁle as an investment that will pay oﬀ in the future, when you are
(re-)running analyses and developing methods on the data. (have a look at the
help page of ?batchTallies to see how to calculate tallies for many samples
genome-wide using a compute cluster).

We will use the `rhdf5::h5write` function to write the data to the tally ﬁle, but
ﬁrst we must set up the tally ﬁle with the correct structure of groups and
datasets. Note that each element of the list that was returned by our call to
applyTallies corresponds to one dataset in the ﬁle.


```{r}
chromlength <- chromdim[chrom,1] #grab the chromosome length from the first sample
study <- "/NRAS" #This will be the name of the main folder in the HDF5 file
tallyFile <- "NRAS.tally.hfs5"
if( file.exists(tallyFile) ){
    file.remove(tallyFile)
}
```

```{r}
if( prepareTallyFile(tallyFile, study, chrom, chromlength, nsamples = length(bamFiles))){
h5ls(tallyFile)
}else{
message( paste( "Preparation of:", tallyFile, "failed" ) )
}
```

> Question: Investigate ?prepareTallyFile and read about the inﬂuence of the
chunkSize and compressionLevel parameters.

## Writing to the HDF5 tally ﬁle

Now that we have set up the ﬁle we can start writing the tally data to it, this
we do using the rhdf5::h5write function on each dataset, specifying the target
ﬁle, location within the ﬁle and the exact block of data we are writing to. For
example the code index = list( NULL, NULL, startpos:endpos ) in the command used
to write the “Coverages” dataset to the ﬁle, speciﬁes that the block of data we
are going to write covers all samples (the ﬁrst NULL) on both strands (the
second NULL) and goes from startpos to endpos in the genomic position dimension.

```{r}
group <- paste(study, chrom, sep="/")
h5write( tallies$Counts, tallyFile, paste( group, "Counts", sep = "/" ),
index = list( NULL, NULL, NULL, startpos:endpos ) )
h5write( tallies$Coverages, tallyFile, paste( group, "Coverages", sep = "/" ),
index = list( NULL, NULL, startpos:endpos ) )
h5write( tallies$Deletions, tallyFile, paste( group, "Deletions", sep = "/" ),
index = list( NULL, NULL, startpos:endpos ) )
h5write( tallies$Reference, tallyFile, paste( group, "Reference", sep = "/" ),
index = list( startpos:endpos ) )
h5ls(tallyFile)
```

Another important aspect of using tally ﬁles is the sample meta-data. Since HDF5
datasets only store matrices without dimension names we need a way of knowing
which id in the sample dimension corresponds to which sample and we probably
want to keep some type of auxiliary information about each sample as well. We
will construct the sample meta-data object (a data.frame) manually and use the
setSampleData function to write is to the tally ﬁle. With the getSampleData
function we can then retrieve the sample meta-data we wrote to the tally ﬁle to
check if everything worked. To familiarise yourself with the required ﬁelds in a
sample meta-data object, have a look at ?setSampleData

```{r}
sampleData <- data.frame(
Sample = gsub( ".bam", "", gsub( pattern = "ExampleData/", "", bamFiles)),
Column = seq_along(bamFiles),
Type = "Control",
Library = "WholeExome",
stringsAsFactors = FALSE
)
sampleData$SampleID <- sapply(
strsplit( sampleData$Sample, "\\."),
function(x) as.numeric(x[2])
)
sampleData$Type[sampleData$SampleID %% 2 == 0] <- "Case"
sampleData$Patient <- paste0( "Patient", floor( (sampleData$SampleID + 1 ) / 2 ) )
sampleData$Library[sampleData$SampleID >= 37] <- "WholeGenome"
setSampleData( tallyFile, group, sampleData, largeAttributes = TRUE )
getSampleData( tallyFile, group )
```

Modifying the sample meta-data is facilitated through the use of getSampleData
and setSampleData, we can for example add another column to the data.frame.

```{r}
sampleData <- getSampleData( tallyFile, group ) #read from file
sampleData$ClinicalVariable <- rnorm(nrow(x = sampleData)) # add some data
setSampleData( tallyFile, group, sampleData, largeAttributes = TRUE ) # write it back
head(getSampleData( tallyFile, group )) #did it work?
```

Special attention has to be paid when mixing largeAttributes = TRUE and the
default of largeAttributes = FALSE when using the setSampleData function, since
they will write the sample meta-data to the tally ﬁle in two diﬀerent ways and
the getSampleData function will always use the data stored with largeAttributes 
= TRUE if it is present.

```{r}
sampleData <- getSampleData( tallyFile, group ) #read from file
sampleData$Sample <- "********"
head(sampleData)
```

```{r}
setSampleData( tallyFile, group, sampleData ) # write it back without largeAttributes=TRUE
sampleData <- getSampleData( tallyFile, group ) #did it work?
head(sampleData) #apparently not
```

## Did we save some space?

Let’s have a look at how much smaller the tally ﬁle is compared to the input
.bam ﬁles.

```{r}
tallySize <- file.info(tallyFile)$size
bamSize <- sum(sapply(
list.files("ExampleData/", pattern= "*.bam$", full.names=TRUE),
function(x) file.info(x)$size )
)
tallySize / bamSize
```

